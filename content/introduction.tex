\chapter{Introduction and overview}
\label{introduction}

In linguistics, \textbf{morphology} refers to alterations to words to reflect changes in meaning or grammatical category. For example, English verbs have differing morphological forms to indicate the simple present and simple past tenses, e.g., \textit{show} $\rightarrow$ \textit{showed}, \textit{see} $\rightarrow$ \textit{saw}, etc. \parencite{Dreyer2008}. Grammatical inflection in particular has a tendency to be structured into \textbf{paradigms} - sets of all possible morphological forms that words of a certain type can take on, often shown arrayed in tables. The table below gives part of the paradigm for the Spanish adjective \textit{pequeño} "large":

\begin{center}
\begin{tabular}{|c||c|c|}
\hline
& singular & plural \\
\hline \hline
masculine & \textit{pequeño} & \textit{pequeños} \\
\hline 
feminine & \textit{pequeña} & \textit{pequeñas} \\
\hline
\end{tabular}
\end{center}

Historically, in language technologies and modeling, morphology has been somewhat under-emphasized. This is probably due at least in part to the dominance of English in language technology research, and its below-average morphological complexity \parencite{Cotterell2017a}. English lexemes tend to have few grammatically inflected forms compared to most other languages. This means that in machine learning models which are given an English training corpus and then tested on new material, the occurrence of \textbf{out-of-vocabulary (OOV)} inflected forms - that is, forms in the test data that never occur in the training data - are less frequent than in some other languages. 

In a more morphologically complex language, a text may contain many inflected forms that are individually rarer but nonetheless perfectly intelligible to a person or model that understands the morphology. For example, a person learning Spanish may have never encountered the form \textit{pequeñas} before, but if they have seen all three other forms of the word and are familiar with Spanish adjectival morphology, they will have no difficulty in fully understanding the meaning of the word. If language models can behave similarly rather than treating a new word like \textit{pequeñas} as OOV - that is, fundamentally unknown - their understanding of new material in morphologically complex languages may be substantially enhanced \parencite{Cotterell2016}. It has been empirically shown that comprehending grammatical categories and inflection improves accuracy rates in language modeling and machine translation \parencite{Faruqui2015}.

The state of the art for modeling morphology since 2016 has been variants of a model type called \textbf{long short-term memory (LSTM) neural networks}, briefly described in \ref{sec:LSTM}, operating over individual characters and grammatical category tags. Their use for computational morphology has been pioneered by SIGMORPHON, a research group that holds annual \textit{shared tasks}, competitions among several research teams on a morphology prediction problem. LSTMs definitively overtook the field after their strong performance relative to other model types in the SIGMORPHON 2016 shared task. However, learning curve analysis in the SIGMORPHON 2017 task showed that LSTMs perform well in high-data settings but, provided with lower volumes of training data, actually fare worse than simpler model types trained on similar amounts of data \parencite{Cotterell2017a}. In the 2018 shared task, an identical morphology prediction task with data for more languages, the learning curve issue was addressed to some degree by \textbf{ensembling} - a means of using the output of several models at once - with other methods \parencite{Cotterell2018b}. For languages with low quantities of digital resources, though, there is still much room for improvement of computational morphology models.

One of the SIGMORPHON 2019 shared tasks focused on \textbf{transfer learning}, leveraging a high volume of data for one language to better model the morphology of another language for which a low volume of data was provided. The research teams tested their models on 100 transfer learning pairs, of which 80 were closely related languages. They claim that this use of data about other languages produced "modest" model performance gains, with data transferred from related languages being more conducive to strengthening models \parencite{McCarthy2019}. This finding produces one potentially useful strategy for leveraging transfer learning to improve modeling of a low-resource language. Unfortunately, there are plenty of low-resource languages not closely related to other high-resource languages. It may be worthwhile to assess what other linguistic properties of a language may predict its usefulness for improving modeling of other languages. 

This study seeks to conduct a more in-depth investigation of the relationships between linguistic typological properties and ultimate transfer learning outcomes for low-resource languages. The computational model distributed as a baseline in SIGMORPHON 2019 was modified to fulfill this task, and 242 pairs of languages were tested as transfer learning pairs, with target languages artificially limited to smaller training data sets to mimic a low availability of structured training data. Performance (as measured by overall accuracy and Levenshtein distance) of these transfer learned models was compared to performance of models lacking a transfer learning component, and absolute differences in performance metrics were taken to represent the efficacy of transfer learning. Alongside this modeling, multiple types of typology information was computationally generated about each language in the study. Finally, statistical relationships were explored between transfer learning efficacy and similarities in these typological characteristics between source and target languages, to understand which types of typological information should be taken into account when designing transfer learning models for low-resource languages.