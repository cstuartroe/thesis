\chapter{Future Work}

There are two major areas for future work to explore that build on the current findings:

Firstly, only relatively rudimentary typological comparisons have been made so far; further linguistic information can be compiled about each language and language pair to determine what other linguistic information is useful for informing transfer learning choices. 

Secondly, since relatively little data about specific model performance and the overall efficacy of transfer learning has been published in prior SIGMORPHON shared tasks, it would be useful to conduct further transfer learning experimentation. Our understanding of how transfer learning functions in computational morphology would be aided by systematically investigating the impact of individual model parameters - foremost the presence or absence of transfer learning, but also potentially the usage of differing attention mechanisms and usage of ensembling between neural and non-neural methods.

\section{Language Features}

There are a number of linguistic typological features that should be possible to gather and may be useful parameters for analysis, including inflection shape (prefixing, suffixing, infixing, introflexion), degree of fusion, and presence of long-distance phonological processes. In addition, obtaining one or more continuous metrics of language relatedness would be useful in working around the statistical confounding that related language pairs appear to introduce.

\subsection{Long-distance phonological processes}

Given that long-distance processes present considerable difficulty for non-neural morphology models, neural models may have to be intensively trained to attend to such processes, presenting an opportunity for transfer learning to leverage existing knowledge.

Presence of long-distance phonological processes will be the most difficult to measure by analyzing the SIGMORPHON data. Fortunately, the presence of vowel and consonant harmony is typically quite binary and pervasive throughout a language's morphology, so rather than attempting to generate a measurement of it may simply be possible hand-annotate languages with a binary indication of whether or not they possess some long-distance process, and perhaps secondarily with a more specific indication of the type (e.g., frontness vowel harmony, sibilant harmony, etc.).

\subsection{Language relatedness metrics}

It may be useful to take into account a more fine-grained measure of language relatedness, so that incidental typological similarities can be successfully statistically blocked against similarities arising from common origin. Two possible strategies are using detailed language genealogical trees and counting degrees of separation between languages, or finding some way to assess lexical similarity, the proportion of words between two languages which have both similar forms and meanings due to shared origin. Lexical similarity may be a more relevant measure - if word stems are similar between two languages, it is likely that grammatical affixes are as well. However, lexical similarity may also be due to shared areal loanwords, such as the profusion of Arabic loanwords into Turkish, Persian, and Urdu. Areal effects can also cause grammatical similarity to spontaneously arise between geographically collocated languages \parencite{Ponti2018}, though grammatical similarities due to shared ancestry are probably stronger. Ultimately, lexical similarity and genealogical closeness measure different types of linguistic relationships, and both should be taken into account if good data is obtainable.

Consistent and quite fine-grained information language genealogy trees can be found on Ethnologue. This study used Ethnologue to generate a three-tiered measure of language relationship, but an even more fine-grained metric of genealogical closeness may be useful. Lexical similarity or other means could be used to measure internal diversity of language families and calibrate a genealogical closeness metric.

Finding good data about lexical similarity looks to be significantly more challenging - certainly, no database exists of pairwise lexical similarity between all languages, and automatically calculating lexical similarity from the SIGMORPHON 2018 data would require semantic or translation information about the words, to identify cognate words with corresponding meanings between languages. Such information may be obtainable via the Google Cloud Translation API. An easier mode of estimation may be via the "Translations" tab of entries on English Wiktionary, which provides translations of a word into a potentially large number of other languages. Average Levenshtein distance between translations for entries into a pair of languages might be a good indicator of overall lexical distance - such a method could be attempted on pairs of languages with known lexical distance to assess its utility.

